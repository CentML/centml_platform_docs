---
title: 'Compute Instance'
description: 'Launch an on-demand GPU instance and start building'
icon: 'microchip'
---

On-demand GPU instances with SSH access to run any GPU-accelerated workloads and let you run, test, and experiment with any AI application seamlessly.

## 1. Select a base image

Spin up a compute instance with your preferred base image (e.g. PyTorch). Enter your ssh public key to configure access to the instance.

<Frame>
    <img src="/images/comp_1.png" style={{ borderRadius: '0.5rem' }} />
</Frame>

Finally, select a GPU instance type and click Deploy.

## 2. SSH into the instance

Once the instance is ready, ssh into the endpoint url provided in the deployment details page with username `centml`.

<Frame>
    <img src="/images/comp_2.png" style={{ borderRadius: '0.5rem' }} />
</Frame>

The instance comes preinstalled with NVIDIA drivers and libraries, as well as those included in your selected base image. Additional packages and libraries can be installed via pip.

```bash
pip install vllm
```


# What's Next

<CardGroup cols={2}>
  <Card
    title="LLM Serving"
    icon="messages"
    href="/apps/llm"
  >
    Explore dedicated public and private endpoints for production model deployments.
 </Card>
  <Card
    title="Clients"
    icon="terminal"
    href="/clients/setup"
  >
    Learn how to interact with the CentML platform programmatically
  </Card>
  <Card
    title="Resources and Pricing"
    icon="coins"
    href="/resources/pricing"
  >
    Learn more about the CentML platform's pricing.
  </Card>
  <Card
    title="Private Inference Endpoints"
    icon="lock"
    href="/resources/private"
  >
Learn how to create private inference endpoints
 </Card>
  <Card
    title="Submit a Support Request"
    icon="headset"
    href="/resources/requesting_support"
  >
    Submit a Support Request.
 </Card>
  <Card
    title="Agents on CentML"
    icon="user-secret"
    href="/resources/json_and_tool"
  >
    Learn how agents can interact with CentML services.
  </Card>
</CardGroup>